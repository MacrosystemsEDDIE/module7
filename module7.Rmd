---
title: "Macrosystems EDDIE Module 7: Using Data to Improve Ecological Forecasts (Activity B)"
author: "Mary Lofton, Tadhg Moore, Quinn Thomas, Cayelan Carey"
date: "3/16/2022"
output: html_document
---
## Set-up (not shown)
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, message = FALSE, warning=FALSE}
# Load libraries ----
library(ggplot2)
library(tidyverse)
library(lubridate)
library(mvtnorm)
library(ncdf4)
```
  
## Define functions
### NEON data functions
#### Function to read in NEON data
```{r}
# Read in NEON data ---- 
#' @param siteID character; four-letter identifier for the NEON site
#' @param var character; short name used to identify NEON variables. See "data/neon_variables.csv"

read_neon_data <- function(siteID, var) {
  idx <- which(neon_vars$Short_name == var)
  read_var <- neon_vars$id[idx]
  units <- neon_vars$units[idx]
  file <- file.path("app","data", "neon", paste0(siteID, "_", read_var, "_", units, ".csv"))
  if(file.exists(file)) {
    df <- read.csv(file)
    df[, 1] <- as.POSIXct(df[, 1], tz =  "UTC")
    colnames(df)[2] <- "value"
    df$var <- neon_vars$id[idx]
    return(df)
  } else {
    stop("File: '", file, "' does not exist.")
  }
}
```

#### Function to get linear model between NEON variables  
In our case, between water temperature and air temperature and shortwave radiation and PAR.  
```{r}
#' fit a linear model between selected NEON variables at a lake site
#'
#' @param siteID name of NEON lake site
#' @param x NEON variable for x axis; choose from NEON short names
#' @param y NEON variable for y axis; choose from NEON short names
#' @param start_date start date for forecast; linear model will be created for #' the 30 most recent observations prior to forecast start date


get_NEON_lm <- function(siteID,x,y,start_date){
  
  #grab x variable
    ref <- x
    x_var <- neon_vars$id[which(neon_vars$Short_name == ref)][1]
    x_units <- neon_vars$units[which(neon_vars$Short_name == ref)][1]
    x_file <- file.path("app/data/neon", paste0(siteID, "_", x_var, "_", x_units, ".csv"))

    xvar <- read.csv(x_file)
    xvar[, 1] <- as.POSIXct(xvar[, 1], tz = "UTC")
    xvar$Date <- as.Date(xvar[, 1])
    xvar <- plyr::ddply(xvar, c("Date"), function(x) mean(x[, 2], na.rm = TRUE)) # Daily average - also puts everything on same timestamp
    xvar <- subset(xvar, xvar$Date < start_date)
    
    #grab y variable
    ref2 <- y
    y_var <- neon_vars$id[which(neon_vars$Short_name == ref2)][1]
    y_units <- neon_vars$units[which(neon_vars$Short_name == ref2)][1]
    y_file <- file.path("app/data/neon", paste0(siteID, "_", y_var, "_", y_units, ".csv"))
    
    yvar <- read.csv(y_file)
    yvar[, 1] <- as.POSIXct(yvar[, 1], tz = "UTC")
    yvar$Date <- as.Date(yvar[, 1])
    if(ref2 == "Surface water temperature") {
      yvar <- yvar[yvar[, 2] == min(yvar[, 2], na.rm = TRUE), c(1, 3)] # subset to Surface water temperature
    }
    yvar <- plyr::ddply(yvar, c("Date"), function(y) mean(y[, 2], na.rm = TRUE)) # Daily average - also puts everything on same timestamp
    yvar <- subset(yvar, yvar$Date < start_date)
    #ok need to merge first and then find rows with no NAs
    
    #merge x and y
    df <- merge(xvar, yvar, by = "Date") %>%
    arrange(desc(Date)) %>% 
    filter(!is.na(V1.x) & !is.na(V1.y)) %>%
    slice(1:30)
    colnames(df)[-1] <- c("X", "Y")
    
    #fit model
    fit <- lm(df[, 3] ~ df[, 2])
    coeffs <- fit$coefficients
    m <- round(coeffs[2], 2)
    b <- round(coeffs[1], 2)
    r2 <- round(summary(fit)$r.squared, 2)
    
    sig <- sigma(fit)
    
    return(list(df = df, fit = fit, m = m, b = b, r2 = r2, sigma = sig))
  }
```

#### Function to format NEON data for input to EnKF
```{r}
#' pulls in variables needed for selected site and NP model and aggregates them
#'
#' @param siteID name of NEON lake site
#' @param neon_vars table of NEON variables available at lake sites; needed because of call to nested read_neon_data function

format_enkf_inputs <- function(siteID, neon_vars){
  
#Drivers
wtemp <- read_neon_data(siteID, "Surface water temperature") %>%
  filter(value == min(value, na.rm = TRUE) ) %>%
  rename(wtemp = V1) %>%
  select(Date,wtemp)

par <- read_neon_data(siteID, "Underwater PAR") %>%
  rename(par = value) %>%
  select(Date,par)

#States
chla <- read_neon_data(siteID, "Chlorophyll-a") %>%
  rename(chla = value) %>%
  select(Date,chla)

din <- read_neon_data(siteID, "Nitrate sensor") %>%
  rename(din = value) %>%
  select(Date,din)

lake_data_00 <- left_join(par,wtemp,by = "Date")
lake_data_0 <- left_join(lake_data_00,chla,by = "Date")
lake_data <- left_join(lake_data_0,din,by = "Date") %>%
  rename(datetime = Date)
return(lake_data)
}

```

#### Function to create input dataset for various frequencies of data assimilation
```{r}
#' students will choose a frequency of data assimilation ranging from monthly to #' daily
#' @param freq_chla frequency of chla data assimilation in days between 1-30
#' @param freq_din frequency of din data assimilation in days between 1-30
#' @param lake_data NEON lake dataset that has been formatted using the format_enkf_inputs function
#' @param start_date start date of forecast (either 2020-09-25 or 2020-10-02)
create_data_assim_inputs <- function(freq_chla, freq_din, lake_data, start_date){
  
  dates <- get_model_dates(as.Date(start_date), as.Date(start_date)+35, time_step = 'days')
  
  a <- 1:35
  b1 <- a[seq(1, length(a), freq_chla)]
  b2 <- a[seq(1, length(a), freq_din)]
  
  out <- lake_data %>%
    select(datetime, chla, din) %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% dates) %>%
    mutate(rownum = row_number(datetime)) %>%
    mutate(chla = ifelse(rownum %in% b1,chla,NA),
           din = ifelse(rownum %in% b2,din,NA)) %>%
    select(-rownum)
  
  return(out)
  
}
```

#### Function to get initial conditions for forecast using formatted NEON lake data
```{r}
#' specify initial conditions as either the observation from the first day of the forecast or the most recent observation
#' @param lake_data NEON lake dataset that has been formatted using the format_enkf_inputs function
#' @param start_date start date of forecast (either 2020-09-25 or 2020-10-02)
get_yini <- function(lake_data, start_date){
  
  yini <- c(NA,NA)
  
  lake_data$datetime = as.Date(lake_data$datetime)

  closest<-function(xv, sv){
  xv[which.min(xv-sv)]}

  if(is.na(lake_data[lake_data[, "datetime"] == as.Date(start_date),"chla"])){
    startrow <- which(lake_data[, "datetime"] == as.Date(start_date))
    NotNA <- lake_data %>% 
      mutate(rownum = c(1:length(lake_data$chla))) %>% 
      filter(!is.na(chla) & datetime < start_date)
    yinirow <- which.min(abs(startrow-NotNA$rownum))
    yini[1] <- NotNA[yinirow,"chla"]
  } else {
      yini[1] <- lake_data[lake_data[, "datetime"] == as.Date(start_date),"chla"]
    }
    
    if(is.na(lake_data[lake_data[, "datetime"] == as.Date(start_date),"din"])){
       startrow <- which(lake_data[, "datetime"] == as.Date(start_date))
    NotNA <- lake_data %>% 
      mutate(rownum = c(1:length(lake_data$din))) %>% 
      filter(!is.na(din) & datetime < start_date)
    yinirow <- which.min(abs(startrow-NotNA$rownum))
    yini[2] <- NotNA[yinirow,"din"]
    } else {
      yini[2] <- lake_data[lake_data[, "datetime"] == as.Date(start_date),"din"]
    }
  
  return(yini)
}
```

### NOAA forecast functions  
#### Function to load NOAA forecast  
```{r}
#' load NOAA GEFS forecast
#'
#' @param siteID name of NEON lake site
#' @param start_date start date for forecast

 load_noaa_forecast <- function(siteID, start_date){
    
      fpath <- file.path("app","data", "NOAAGEFS_1hr", siteID)
      fpath2 <- file.path(fpath, start_date, "00")
      fils <<- list.files(fpath2)
      fils <<- fils[-c(grep("ens00", fils))]
      fid <- nc_open(file.path(fpath2, fils[1]))
      vars <- fid$var # Extract variable names for selection
      fc_vars <<- names(vars)
      membs <<- length(fils)
      
      out <- lapply(start_date, function(dat) {
        idx <- which(start_date == dat)
        
        fpath2 <- file.path(fpath, dat, "00")
        fils <- list.files(fpath2)
        fils <- fils[-c(grep("ens00", fils))]
        
        for( i in seq_len(length(fils))) {
          
          fid <- ncdf4::nc_open(file.path("app","data", "NOAAGEFS_1hr", siteID, dat,
                                          "00", fils[i]))
          tim = ncvar_get(fid, "time")
          tunits = ncatt_get(fid, "time")
          lnam = tunits$long_name
          tustr <- strsplit(tunits$units, " ")
          step = tustr[[1]][1]
          tdstr <- strsplit(unlist(tustr)[3], "-")
          tmonth <- as.integer(unlist(tdstr)[2])
          tday <- as.integer(unlist(tdstr)[3])
          tyear <- as.integer(unlist(tdstr)[1])
          tdstr <- strsplit(unlist(tustr)[4], ":")
          thour <- as.integer(unlist(tdstr)[1])
          tmin <- as.integer(unlist(tdstr)[2])
          origin <- as.POSIXct(paste0(tyear, "-", tmonth, 
                                      "-", tday, " ", thour, ":", tmin), 
                               format = "%Y-%m-%d %H:%M", tz = "UTC")
          if (step == "hours") {
            tim <- tim * 60 * 60
          }
          if (step == "minutes") {
            tim <- tim * 60
          }
          time = as.POSIXct(tim, origin = origin, tz = "UTC")
          var_list <- lapply(fc_vars, function(x) {
            data.frame(time = time, value = ncdf4::ncvar_get(fid, x))
          }) 
          
          
          ncdf4::nc_close(fid)
          names(var_list) <- fc_vars
          
          mlt1 <- reshape::melt(var_list, id.vars = "time")
          mlt1 <- mlt1[, c("time", "L1", "value")]
          
          # df <- get_vari(file.path("data", fils[i]), input$fc_var, print = F)
          cnam <- paste0("ens", formatC(i, width = 2, format = "d", flag = "0"))
          if(i == 1) {
            df2 <- mlt1
            colnames(df2)[3] <- cnam
          } else {
            df2 <- merge(df2, mlt1, by = c(1,2))
            colnames(df2)[ncol(df2)] <- cnam
          }
          
        }
        return(df2)
      })
      
      names(out) <- start_date
      return(out)
      
      
    }
```
#### Function to convert NOAA forecast to water temp and uPAR forecasts
```{r}
#' convert NOAA GEFS forecast to water temperature and uPAR forecast using
#' output from linear regression models of NEON variables
#'
#' @param start_date start date for forecast
#' @param lm_wt output of get_NEON_lm function for air temperature and water temperature
#' @param lm_upar output of get_NEON_lm function for shortwave radiation and uPAR
#' @param fc NOAA GEFS forecast with a start date equal to start_date

convert_forecast <- function(lm_wt, lm_upar, fc, start_date){
  
    coeffs_wt <- lm_wt$fit$coefficients
    m_wt <- round(coeffs_wt[2], 2)
    b_wt <- round(coeffs_wt[1], 2)
    sigma_wt <- lm_wt$sigma
    
    coeffs_upar <- lm_upar$fit$coefficients
    m_upar <- round(coeffs_upar[2], 2)
    b_upar <- round(coeffs_upar[1], 2)
    sigma_upar <- lm_upar$sigma

    fc_data = fc
    
    fc_idx <- fc_data[[start_date]]
    
    fc_conv_list <- lapply(1:30, function(x) {
      df <- fc_idx
      sub <- df[(df[, 2] %in% c("air_temperature",
                                "surface_downwelling_shortwave_flux_in_air",
                                "precipitation_flux")), c(1, 2, 2 + x)]
      df2 <- tidyr::pivot_wider(data = sub, id_cols = time, names_from = L1, values_from = 3)
      df2$air_temperature <- df2$air_temperature - 273.15
      df2$date <- as.Date(df2$time)
      df2$time <- NULL
      df3 <- plyr::ddply(df2, "date", function(x){
        colMeans(x[, 1:3], na.rm = TRUE)
      })
      # df3 <- df3[2:16, ]
      fc_out_dates <<- df3$date
      df3$wtemp <- rnorm(length(df3$air_temperature),m_wt * df3$air_temperature + b_wt,sigma_wt)
      df3$upar <- rnorm(length(df3$surface_downwelling_shortwave_flux_in_air),m_upar * df3$surface_downwelling_shortwave_flux_in_air + b_upar,sigma_upar)
      
      df3 <- df3[, c("date", "wtemp", "upar")]
      df3$fc_date <- start_date
      return(df3)
    })
    
    l1 <- fc_conv_list
    idvars <- colnames(l1[[1]])
    mlt1 <- reshape::melt(l1, id.vars = idvars)
    
    return(mlt1)
  }
```


### NP model functions  
#### Function to define NP model
IMPORTANT!! This is not quite the same model as would have been used in Module 5 because I've adapted it to play nicely with Jake's EnKF functions. So that might require some re-coordinating of code for Activity A, Objective 6 compared to what currently exists.
```{r}

# Define NP model
# this has been adapted to play nicely with Jake's EnKF functions

NP_model <- function(PHYTO, DIN, TEMP, PAR, maxUptake){

  #STATES
  curr_PHYTO = PHYTO
  curr_DIN = DIN
  
  #PARAMETERS
  maxUptake = maxUptake #day-1; this is the only parameter we are tuning
  kspar=120 #uEinst m-2 s-1
  ksdin=0.5 #mmol m-3
  maxGrazing=1.0 # day-1
  ksphyto=1 #mmol N m-3
  pFaeces=0.3 #unitless
  mortalityRate=0.01 #(mmmolN m-3)-1 day-1
  excretionRate=0.1 #day-1
  mineralizationRate=0.1 #day-1
  Chl_Nratio = 0.1 #mg chl (mmolN)-1
  Q10 = 2  #unitless
  refTEMP = 20
  N_Load = 0.2

  #DRIVERS
  PAR <- PAR
  TEMP <- TEMP 

  #FLUX EQUATIONS HERE
  Temp_effect = Q10^((TEMP-refTEMP)/10)
  N_Uptake <- maxUptake*curr_PHYTO*(PAR/(PAR+kspar))*(curr_DIN/(curr_DIN+ksdin))*Temp_effect

  Mortality <- mortalityRate*curr_PHYTO^2
  Mineralization <- mineralizationRate * Temp_effect

  #predicted values
  PHYTO_pred = curr_PHYTO + N_Uptake - Mortality
  DIN_pred = curr_DIN + Mortality - N_Uptake + N_Load

  return(list(PHYTO_pred = PHYTO_pred,
              DIN_pred = DIN_pred,
              maxUptake = maxUptake))   # the ordinary output variables
}


```
### ENKF functions from Jake Zwart GLEON workshop
#### Function to create vector of model timesteps
```{r}
#' retreive the model time steps based on start and stop dates and time step
#'
#' @param model_start model start date in date class
#' @param model_stop model stop date in date class
#' @param time_step model time step, defaults to daily timestep
get_model_dates = function(model_start, model_stop, time_step = 'days'){
  
  model_dates = seq.Date(from = as.Date(model_start), to = as.Date(model_stop), by = time_step)
  
  return(model_dates)
}
```
#### Function to create vector to hold states and parameters for updating
```{r}
#' vector for holding states and parameters for updating
#'
#' @param n_states number of states we're updating in data assimilation routine
#' @param n_params_est number of parameters we're calibrating
#' @param n_step number of model timesteps
#' @param n_en number of ensembles
get_Y_vector = function(n_states, n_params_est, n_step, n_en){
  
  Y = array(dim = c(n_states + n_params_est, n_step, n_en))
  
  return(Y)
}
```
#### Function to create observation error matrix
```{r}
#' observation error matrix, should be a square matrix where
#'   col & row = the number of states and params for which you have observations
#'
#' @param n_states number of states we're updating in data assimilation routine
#' @param n_param_obs number of parameters for which we have observations
#' @param n_step number of model timesteps
#' @param state_sd vector of state observation standard deviation; assuming sd is constant through time
#' @param param_sd vector of parameter observation standard deviation; assuming sd is constant through time
get_obs_error_matrix = function(n_states, n_params_obs, n_step, state_sd, param_sd){
  
  R = array(0, dim = c(n_states + n_params_obs, n_states + n_params_obs, n_step))
  
  state_var = state_sd^2 #variance of temperature observations
  
  param_var = param_sd^2
  
  if(n_params_obs > 0){
    all_var = c(state_var, param_var)
  }else{
    all_var = state_var
  }
  
  for(i in 1:n_step){
    # variance is the same for each depth and time step; could make dynamic or varying by time step if we have good reason to do so
    R[,,i] = diag(all_var, n_states + n_params_obs, n_states + n_params_obs)
  }
  
  return(R)
}

```
#### Function to create matrix that identifies when observations are available
```{r}
#' Measurement operator matrix saying 1 if there is observation data available, 0 otherwise
#'
#' @param n_states number of states we're updating in data assimilation routine
#' @param n_param_obs number of parameters for which we have observations
#' @param n_params_est number of parameters we're calibrating
#' @param n_step number of model timesteps
#' @param obs observation matrix created with get_obs_matrix function
get_obs_id_matrix = function(n_states, n_params_obs, n_params_est, n_step, obs){
  
  H = array(0, dim=c(n_states + n_params_obs, n_states + n_params_est, n_step))
  
  # order goes 1) states, 2)params for which we have obs, 3) params for which we're estimating but don't have obs
  
  for(t in 1:n_step){
    H[1:(n_states + n_params_obs), 1:(n_states + n_params_obs), t] = diag(ifelse(is.na(obs[,,t]),0, 1), n_states + n_params_obs, n_states + n_params_obs)
  }
  
  return(H)
}

```
#### Function to turn observation dataframe into matrix
```{r}
#' turn observation dataframe into matrix
#'
#' @param obs_df observation data frame
#' @param model_dates dates over which you're modeling
#' @param n_step number of model time steps
#' @param n_states number of states we're updating in data assimilation routine
#' @param states character string vector of state names in obs_file

get_obs_matrix = function(obs_df, model_dates, n_step, n_states, states){
  
  # need to know location and time of observation
  
  obs_df_filtered = obs_df %>%
    dplyr::filter(as.Date(datetime) %in% model_dates) %>%
    mutate(date = as.Date(datetime)) %>%
    select(date, chla, din) %>%
    mutate(date_step = which(model_dates %in% date))

  obs_matrix = array(NA, dim = c(n_states, 1, n_step))

  for(i in 1:n_states){
  for(j in obs_df_filtered$date_step){
    obs_matrix[i, 1, j] = dplyr::filter(obs_df_filtered,
                                        date_step == j) %>%
      pull(states[i])
  }}
  
  return(obs_matrix)
}


```
#### Kalman filter function
```{r}
##' @param Y vector for holding states and parameters you're estimating
##' @param R observation error matrix
##' @param obs observations at current timestep
##' @param H observation identity matrix
##' @param n_en number of ensembles
##' @param cur_step current model timestep
kalman_filter = function(Y, R, obs, H, n_en, cur_step){
  
  cur_obs = obs[ , , cur_step]
  
  cur_obs = ifelse(is.na(cur_obs), 0, cur_obs) # setting NA's to zero so there is no 'error' when compared to estimated states
  
  ###### estimate the spread of your ensembles #####
  Y_mean = matrix(apply(Y[ , cur_step, ], MARGIN = 1, FUN = mean), nrow = length(Y[ , 1, 1])) # calculating the mean of each temp and parameter estimate
  delta_Y = Y[ , cur_step, ] - matrix(rep(Y_mean, n_en), nrow = length(Y[ , 1, 1])) # difference in ensemble state/parameter and mean of all ensemble states/parameters
  
  ###### estimate Kalman gain #########
  K = ((1 / (n_en - 1)) * delta_Y %*% t(delta_Y) %*% t(H[, , cur_step])) %*%
    qr.solve(((1 / (n_en - 1)) * H[, , cur_step] %*% delta_Y %*% t(delta_Y) %*% t(H[, , cur_step]) + R[, , cur_step]))
  
  ###### update Y vector ######
  for(q in 1:n_en){
    Y[, cur_step, q] = Y[, cur_step, q] + K %*% (cur_obs - H[, , cur_step] %*% Y[, cur_step, q]) # adjusting each ensemble using kalman gain and observations
  }
  return(Y)
}

```
#### Function to initialize state and parameter vector
```{r}
#' initialize Y vector with draws from distribution of obs
#'
#' @param Y Y vector
#' @param obs observation matrix
initialize_Y = function(Y, obs, init_params, n_states_est, n_params_est, n_params_obs, n_step, n_en, state_sd, param_sd, yini){
  
  # initializing states with earliest observations and parameters
  first_obs = yini #%>% # turning array into list, then using coalesce to find first obs in each position.
    #ifelse(is.na(.), mean(., na.rm = T), .) # setting initial temp state to mean of earliest temp obs from other sites if no obs
  #MEL omitting this for now - can build back in later if needed
  
  if(n_params_est > 0){
    first_params = init_params
  }else{
    first_params = NULL
  }
  
  Y[ , 1, ] = array(abs(rnorm(n = n_en * (n_states_est + n_params_est),
                              mean = c(first_obs, first_params),
                              sd = c(state_sd, param_sd))),
                    dim = c(c(n_states_est + n_params_est), n_en))
  
  return(Y)
}
```
#### Function to create driver data matrix
```{r}
#' matrix for holding driver data
#'
#' @param drivers_df dataframe which holds all the driver data 
#' @param model_dates dates for model run 
#' @param n_drivers number of model drivers 
#' @param driver_colnames column names of the drivers in the driver dataframe 
#' @param driver_cv coefficient of variation for each driver data 
#' @param n_step number of model timesteps
#' @param n_en number of ensembles
get_drivers = function(fc_conv, n_drivers, driver_colnames, model_dates, n_en){

  drivers_out = array(NA, dim = c(length(model_dates), n_drivers, n_en))
  
  for(i in 1:n_drivers){
    for(j in 1:length(model_dates)){
      fc1 <- fc_conv %>% filter(date == model_dates[j])
      drivers_out[j,i,] = fc1[,driver_colnames[i]]
                               
    }
  }
  
  return(drivers_out) 
}

```
#### EnKF wrapper
```{r}
#' wrapper for running EnKF 
#' 
#' @param n_en number of model ensembles 
#' @param start start date of model run 
#' @param stop date of model run
#' @param time_step model time step, defaults to days 
#' @param obs_file observation file 
#' @param driver_file driver data file 
#' @param n_states_est number of states we're estimating 
#' @param n_params_est number of parameters we're estimating 
#' @param n_params_obs number of parameters for which we have observations 
#' @param decay_init initial decay rate of DOC 
#' @param obs_cv coefficient of variation of observations 
#' @param param_cv coefficient of variation of parameters 
#' @param init_cond_cv initial condition CV 
#' @param state_names character string vector of state names as specified in obs_file
#' @param yini vector of initial conditions for states (chla, din)

EnKF = function(n_en = 30, 
                start = '2020-09-25', # start date 
                stop = '2020-10-29', 
                time_step = 'days', 
                obs_file = lake_data_no_assim,
                driver_file = fc_conv,
                n_states_est = 2, 
                n_params_est = 1,
                n_params_obs = 0, 
                maxUptake_init = 0.1, 
                obs_cv = c(0.2, 0.1),
                param_cv = 0.1,
                init_cond_cv = c(0.1, 0.1),
                state_names = c("chla","din"),
                yini = c(7.21, 1.39)){
  
  
  n_en = n_en
  start = as.Date(start)
  stop = as.Date(stop)
  time_step = 'days' 
  dates = get_model_dates(model_start = start, model_stop = stop, time_step = time_step)
  n_step = length(dates)
  
  # get observation matrix
  obs_df = obs_file %>% 
    select(datetime, chla, din) 
  
  n_states_est = n_states_est # number of states we're estimating 
  
  n_params_est = n_params_est # number of parameters we're calibrating
  
  n_params_obs = n_params_obs # number of parameters for which we have observations
  
  maxUptake_init = maxUptake_init # Initial estimate of DOC decay rate day^-1 
  
  yini <- c( #initial estimate of PHYTO and DIN states, respectively
  PHYTO = yini[1], #mmolN m-3 which is the same as mg chl b/c ratio set to 1
  DIN = yini[2]) #mmolN m-3
  
  state_cv = obs_cv #coefficient of variation of chla and din observations, respectively 
  state_sd = state_cv * yini
  init_cond_sd = init_cond_cv * yini
  
  param_cv = param_cv #coefficient of variation of maxUptake 
  param_sd = param_cv * maxUptake_init
  
  # setting up matrices
  # observations as matrix
  obs = get_obs_matrix(obs_df = obs_df,
                       model_dates = dates,
                       n_step = n_step,
                       n_states = n_states_est,
                       states = state_names)
  
  # Y vector for storing state / param estimates and updates
  Y = get_Y_vector(n_states = n_states_est,
                   n_params_est = n_params_est,
                   n_step = n_step,
                   n_en = n_en)
  
  # observation error matrix
  R = get_obs_error_matrix(n_states = n_states_est,
                           n_params_obs = n_params_obs,
                           n_step = n_step,
                           state_sd = state_sd,
                           param_sd = param_sd)
  
  # observation identity matrix
  H = get_obs_id_matrix(n_states = n_states_est,
                        n_params_obs = n_params_obs,
                        n_params_est = n_params_est,
                        n_step = n_step,
                        obs = obs)
  
  # initialize Y vector
  Y = initialize_Y(Y = Y, obs = obs, init_params = maxUptake_init, n_states_est = n_states_est,
                   n_params_est = n_params_est, n_params_obs = n_params_obs,
                   n_step = n_step, n_en = n_en, state_sd = init_cond_sd, param_sd = param_sd, yini = yini)
  
  # get driver data with uncertainty - dim = c(n_step, driver, n_en) 
  drivers = get_drivers(fc_conv = driver_file, 
                        model_dates = dates,
                        n_drivers = 2, 
                        driver_colnames = c('wtemp', 'upar'), 
                        n_en = n_en) 
  
  # start modeling
  for(t in 2:n_step){
    for(n in 1:n_en){
      
      # run model; 
      model_output = NP_model(TEMP = drivers[t-1, 1, n], 
                                      PHYTO = Y[1, t-1, n], 
                                      DIN = Y[2, t-1, n], 
                                      PAR = drivers[t-1, 2, n],
                                      maxUptake = Y[3, t-1, n])
      
      ######quick hack to add in process error (ha!)########
      
      #specify Y_star (mean of multivariate normal)
      Y_star = matrix(c(model_output$PHYTO_pred, model_output$DIN_pred, model_output$maxUptake))
      
      #specify sigma (covariance matrix of states and updating parameters)
      residual_matrix <- matrix(NA, nrow = 4, ncol = 3)
      residual_matrix[1,] <- c(0.5, 0.3, 0.01)
      residual_matrix[2,] <- c(1, 0.2, 0.02)
      residual_matrix[3,] <- c(0.25, 0.1, 0.03)
      residual_matrix[4,] <- c(-0.30, -0.1, -0.03)

      sigma_proc <- cov(residual_matrix)
      
      #make a draw from Y_star
      Y_draw = abs(rmvnorm(1, mean = Y_star, sigma = sigma_proc))
      Y[1 , t, n] = Y_draw[1] # store in Y vector
      Y[2 , t, n] = Y_draw[2]
      Y[3 , t, n] = Y_draw[3]
      
      #####end of hack######################################
    }
    # check if there are any observations to assimilate 
    if(any(!is.na(obs[ , , t]))){
      Y = kalman_filter(Y = Y,
                        R = R,
                        obs = obs,
                        H = H,
                        n_en = n_en,
                        cur_step = t) # updating params / states if obs available
    }
  }
  out = list(Y = Y, dates = dates, drivers = drivers, R = R, obs = obs, state_sd = state_sd)
  
  return(out)
}


```
#### Function to calculate RMSE
```{r}
#' calculate RMSE of ensemble mean vs. observations 
#' 
#' @param est_out forecast output from EnKF wrapper 
#' @param lake_data NEON data for selected site formatted using format_enkf_inputs function

rmse <- function(est_out, lake_data){
  
  #get ensemble mean
  mean_chla_est = apply(est_out$Y[1,,] , 1, FUN = mean)
  mean_din_est = apply(est_out$Y[2,,] , 1, FUN = mean)

  
  #limit obs to forecast dates
  lake_data1 <- lake_data %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% est_out$dates)
  
  #calculate RMSE
  rmse_chla <- sqrt(mean((lake_data1$chla - mean_chla_est)^2, na.rm = TRUE))
  rmse_nitrate <- sqrt(mean((lake_data1$din - mean_din_est)^2, na.rm = TRUE))
  
  return(list(rmse_chla = rmse_chla, rmse_nitrate = rmse_nitrate))


}

```


### Plotting functions  
#### Functions to plot chl-a forecast
```{r}
#' plot chlorophyll forecast and observations 
#' 
#' @param est_out forecast output from EnKF wrapper 
#' @param lake_data NEON data for selected site formatted using format_enkf_inputs function

plot_chla = function(est_out, lake_data){
  mean_chla_est = apply(est_out$Y[1,,] , 1, FUN = mean)
  lake_data <- lake_data %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% est_out$dates)
  plot(mean_chla_est ~ est_out$dates, type ='l', 
       ylim = range(est_out$Y[1,,], na.rm = TRUE ),
       col = 'grey', ylab = 'chla (mg L-1)', xlab = '')
  for(i in 2:n_en){
    lines(est_out$Y[1,,i]  ~ est_out$dates, 
          col = 'grey')
  }
  lines(mean_chla_est ~ est_out$dates, col = 'black', lwd =2 )
  points(lake_data$chla[1:35]  ~ 
           est_out$dates[1:35], pch = 16, col = 'blue')
  points(est_out$obs[1,,]  ~ 
           est_out$dates, pch = 16, col = 'red')
  arrows(est_out$dates[1:35], lake_data$chla[1:35]  - est_out$state_sd[1], 
         est_out$dates[1:35], lake_data$chla[1:35]  + est_out$state_sd[1], 
         code = 3, length = 0.1, angle = 90, col = 'blue')
  arrows(est_out$dates, est_out$obs[1,,]  - est_out$state_sd[1], 
         est_out$dates, est_out$obs[1,,]  + est_out$state_sd[1], 
         code = 3, length = 0.1, angle = 90, col = 'red')
}

```

#### Function to plot DIN forecast
```{r}
#' plot nitrate forecast and observations 
#' 
#' @param est_out forecast output from EnKF wrapper 
#' @param lake_data NEON data for selected site formatted using format_enkf_inputs function
plot_nitrate = function(est_out, lake_data){
  mean_din_est = apply(est_out$Y[2,,] , 1, FUN = mean)
  lake_data <- lake_data %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% est_out$dates)
  plot(mean_din_est ~ est_out$dates, type ='l', 
       ylim = range(est_out$Y[2,,],na.rm = TRUE ),
       col = 'grey', ylab = 'Nitrate (um L-1)', xlab = '')
  for(i in 2:n_en){
    lines(est_out$Y[2,,i]  ~ est_out$dates, 
          col = 'grey')
  }
  lines(mean_din_est ~ est_out$dates, col = 'black', lwd =2 )
  points(lake_data$din[2:35]  ~ 
           est_out$dates[2:35], pch = 16, col = 'blue')
  arrows(est_out$dates[2:35], lake_data$din[2:35]  - est_out$state_sd[2], 
         est_out$dates[2:35], lake_data$din[2:35]  + est_out$state_sd[2], 
         code = 3, length = 0.1, angle = 90, col = 'blue')
  points(est_out$obs[2,,]  ~ 
           est_out$dates, pch = 16, col = 'red')
  arrows(est_out$dates, est_out$obs[2,,]  - est_out$state_sd[2], 
         est_out$dates, est_out$obs[2,,]  + est_out$state_sd[2], 
         code = 3, length = 0.1, angle = 90, col = 'red')
}
```

#### Function to plot maxUptake parameter
```{r}
#' plot maxUptake parameter forecast 
#' 
#' @param est_out forecast output from EnKF wrapper 

plot_maxUptake = function(est_out){
  mean_maxUptake_est = apply(est_out$Y[3,,], 1, FUN = mean)
  plot(mean_maxUptake_est ~ est_out$dates, type ='l', 
       ylim = range(est_out$Y[3,,]),
       col = 'grey', ylab = 'maxUptake (day^-1)', xlab ='')
  for(i in 2:n_en){
    lines(est_out$Y[3,,i] ~ est_out$dates, col = 'grey')
  }
  lines(mean_maxUptake_est ~ est_out$dates, col = 'black', lwd = 2)
}
```
#### Function to plot predictions vs. observations for chl-a
```{r}
#' plot chl-a mean forecast and observations 
#' 
#' @param est_out forecast output from EnKF wrapper 
#' @param lake_data NEON data for selected site formatted using format_enkf_inputs function
pred_v_obs_chla = function(est_out, lake_data){
  mean_chla_est = apply(est_out$Y[1,,] , 1, FUN = mean)
  
  # this could be used to show a 95% confidence error bar on predicted
  # but I think the error bars make the plot a bit hard to read
  # top_din_est = apply(est_out$Y[2,,] , 1, FUN = quantile, probs=c(0.975))
  # bottom_din_est = apply(est_out$Y[2,,] , 1, FUN = quantile, probs=c(0.025))

  lake_data <- lake_data %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% est_out$dates)
  plot(mean_chla_est ~ lake_data$chla, type ='p', 
       ylim = c(min(c(range(mean_chla_est,na.rm = TRUE),range(lake_data$chla,na.rm = TRUE))),c(max(c(range(mean_chla_est,na.rm = TRUE),range(lake_data$chla,na.rm = TRUE))))),
       xlim = c(min(c(range(mean_chla_est,na.rm = TRUE),range(lake_data$chla,na.rm = TRUE))),c(max(c(range(mean_chla_est,na.rm = TRUE),range(lake_data$chla,na.rm = TRUE))))),
       col = 'black', ylab = 'predicted Chl-a (ug L-1)', xlab = 'observed Chl-a (ug L-1)')
  abline(a=0, b=1)
  
  #this code could be used to show error bars representing uncertainty but 
  #I think it makes the plot kinda hard to read
  # arrows(lake_data$din[1:35]  - est_out$state_sd[2], mean_din_est,
  #        lake_data$din[1:35]  + est_out$state_sd[2], mean_din_est, 
  #        code = 3, length = 0.1, angle = 90, col = 'black')
  # arrows(lake_data$din, mean_din_est  - est_out$state_sd[2], 
  #        lake_data$din, mean_din_est  + est_out$state_sd[2], 
  #        code = 3, length = 0.1, angle = 90, col = 'black')
}
```
#### Function to plot predictions vs. observations for nitrate
```{r}
#' plot nitrate forecast and observations 
#' 
#' @param est_out forecast output from EnKF wrapper 
#' @param lake_data NEON data for selected site formatted using format_enkf_inputs function
pred_v_obs_nitrate = function(est_out, lake_data){
  mean_din_est = apply(est_out$Y[2,,] , 1, FUN = mean)
  
  # this could be used to show a 95% confidence error bar on predicted
  # but I think the error bars make the plot a bit hard to read
  # top_din_est = apply(est_out$Y[2,,] , 1, FUN = quantile, probs=c(0.975))
  # bottom_din_est = apply(est_out$Y[2,,] , 1, FUN = quantile, probs=c(0.025))

  lake_data <- lake_data %>%
    mutate(datetime = as.Date(datetime)) %>%
    filter(datetime %in% est_out$dates)
  plot(mean_din_est ~ lake_data$din, type ='p', 
       ylim = c(min(c(range(mean_din_est,na.rm = TRUE),range(lake_data$din,na.rm = TRUE))),c(max(c(range(mean_din_est,na.rm = TRUE),range(lake_data$din,na.rm = TRUE))))),
       xlim = c(min(c(range(mean_din_est,na.rm = TRUE),range(lake_data$din,na.rm = TRUE))),c(max(c(range(mean_din_est,na.rm = TRUE),range(lake_data$din,na.rm = TRUE))))),
       col = 'black', ylab = 'predicted Nitrate (um L-1)', xlab = 'observed Nitrate (um L-1)')
  abline(a=0, b=1)
  
  #this code could be used to show error bars representing uncertainty but 
  #I think it makes the plot kinda hard to read
  # arrows(lake_data$din[1:35]  - est_out$state_sd[2], mean_din_est,
  #        lake_data$din[1:35]  + est_out$state_sd[2], mean_din_est, 
  #        code = 3, length = 0.1, angle = 90, col = 'black')
  # arrows(lake_data$din, mean_din_est  - est_out$state_sd[2], 
  #        lake_data$din, mean_din_est  + est_out$state_sd[2], 
  #        code = 3, length = 0.1, angle = 90, col = 'black')
}
```


## Objective 7: Assimilate data  
This objective introducees students to data assimilation by asking students to generate forecasts:  
A. using initial conditions based on the most recent chl-a and nitrate observations but no subsequent data assimilation  
B. that assimilate chl-a data at a "medium" frequency (every 10 days)  
C. that assimilate nitrate data at a "medium" frequency (every 10 days)  
D. that assimilate both chl-a and nitrate data every 10 days  
The desired learning outcome is for students to understand that data assimilation corrects model predictions and improves forecast performance as assessed by RMSE calculated for the mean ensemble prediction and observations.    
### Set-up
```{r}
# Load in NEON sites dataframe ----
neon_sites_df <- read.csv("./app/data/neon_sites.csv")
neon_sites_df$long <- round(neon_sites_df$long, 3)
neon_sites_df$lat <- round(neon_sites_df$lat, 3)

# Reference for downloading variables ----
neon_vars <- read.csv("./app/data/neon_variables.csv")

# Objective 1 - Site Selection ----
print(neon_sites_df$siteID)
#we have BARC, CRAM, LIRO, PRLA, PRPO, SUGG, TOOK
#need to think about which sites we want to use for Mod 7 based on how they behave in app testing
siteID <- "BARC"

#set start date of forecast
start_date = "2020-09-25" 

#load NEON data and format for input into EnKF
lake_data <- format_enkf_inputs(siteID = siteID, neon_vars = neon_vars)

#get initial conditions for forecast
yini <- get_yini(lake_data = lake_data,
                 start_date = start_date)

#load NOAA GEFS forecast
fc <- load_noaa_forecast(siteID = siteID, start_date = start_date)

#get regression for water temp
lm_wt <- get_NEON_lm(siteID = siteID, x = "Air temperature",
                     y = "Surface water temperature", start_date = start_date)

#get regression for upar
lm_upar <- get_NEON_lm(siteID = siteID, x = "Shortwave radiation",
                     y = "Underwater PAR", start_date = start_date)

#convert NOAA GEFS forecast to water temp and upar forecast
driver_file <- convert_forecast(lm_wt = lm_wt, lm_upar = lm_upar, fc = fc, start_date = start_date)
```
### Run forecast with no data assimilation  
In this case, inserting 36 as the frequency of chl-a and nitrate assimilation ensures that only the first observation in the 35 day observation period will be assimilated. If there are no chl-a or nitrate data available on the start date of the forecast, the get_yini function will pull in the most recent observation prior to the forecast start date as the initial condition for that variable.
```{r}
#format observation data file depending on selected frequency of data assimilation

obs_file <- create_data_assim_inputs(freq_chla = 36,
                                     freq_din = 36,
                                     lake_data = lake_data,
                                     start_date = start_date)

n_en = 30 # how many ensemble members 

#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-09-25', # start date 
           stop = '2020-10-29', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(0.01,0.05),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data) 
plot_nitrate(est_out = est_out, lake_data = lake_data) 
plot_maxUptake(est_out) 
pred_v_obs_chla(est_out = est_out, lake_data = lake_data)
pred_v_obs_nitrate(est_out = est_out, lake_data = lake_data)
rmse(est_out = est_out, lake_data = lake_data)


```
### Run forecast with chl-a data assimilated every 10 days  
Notice that the freq_chla argument in the create_data_assim_inputs file has been adjusted to 10. If chl-a data is not available on the 10th, 20th, or 30th days, the value for that day will be NA and the forecast function will proceed without assimilating chl-a data for that day.
```{r}
#format observation data file depending on selected frequency of data assimilation

obs_file <- create_data_assim_inputs(freq_chla = 10,
                                     freq_din = 36,
                                     lake_data = lake_data,
                                     start_date = start_date)

n_en = 30 # how many ensemble members 

#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-09-25', # start date 
           stop = '2020-10-29', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data) 
plot_nitrate(est_out = est_out, lake_data = lake_data) 
plot_maxUptake(est_out) 
pred_v_obs_chla(est_out = est_out, lake_data = lake_data)
pred_v_obs_nitrate(est_out = est_out, lake_data = lake_data)
rmse(est_out = est_out, lake_data = lake_data)

```
### Run forecast with nitrate data assimilated every 10 days  
Notice that the freq_din argument in the create_data_assim_inputs file has been adjusted to 10. If nitrate data is not available on the 10th, 20th, or 30th days, the value for that day will be NA and the forecast function will proceed without assimilating nitrate data for that day.
```{r}
#format observation data file depending on selected frequency of data assimilation

obs_file <- create_data_assim_inputs(freq_chla = 36,
                                     freq_din = 10,
                                     lake_data = lake_data,
                                     start_date = start_date)

n_en = 30 # how many ensemble members 

#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-09-25', # start date 
           stop = '2020-10-29', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data) 
plot_nitrate(est_out = est_out, lake_data = lake_data) 
plot_maxUptake(est_out) 
pred_v_obs_chla(est_out = est_out, lake_data = lake_data)
pred_v_obs_nitrate(est_out = est_out, lake_data = lake_data)
rmse(est_out = est_out, lake_data = lake_data)

```
### Run forecast with both chl-a and nitrate data assimilated every 10 days  
```{r}
#format observation data file depending on selected frequency of data assimilation
obs_file <- create_data_assim_inputs(freq_chla = 10,
                                     freq_din = 10,
                                     lake_data = lake_data,
                                     start_date = start_date)

n_en = 30 # how many ensemble members 

#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-09-25', # start date 
           stop = '2020-10-29', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data) 
plot_nitrate(est_out = est_out, lake_data = lake_data) 
plot_maxUptake(est_out) 
pred_v_obs_chla(est_out = est_out, lake_data = lake_data)
pred_v_obs_nitrate(est_out = est_out, lake_data = lake_data)
rmse(est_out = est_out, lake_data = lake_data)

```

## Objective 8: Explore observation uncertainty  
This objective will ask students to adjust the observation uncertainty associated with chl-a and nitrate data. The learning outcome of the objective is for students to understand that the amount of uncertainty associated with observations determines how much the model corrects itself to align with those observations. In the Shiny app, students will use sliders to adjust the values of the obs_cv argument to the EnKF function. Below are two examples: one when observation uncertainty for both variables is low, and one when it is high.  

### Low observation uncertainty
```{r}
#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-09-25', # start date 
           stop = '2020-10-29', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(0.02,0.02),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data) 
plot_nitrate(est_out = est_out, lake_data = lake_data) 
plot_maxUptake(est_out) 
#not plotting pred vs. obs or calculating RMSE here as the focus is on the behavior of the ensemble, not the forecast accuracy

```
### High observation uncertainty
```{r}
#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-09-25', # start date 
           stop = '2020-10-29', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(0.5,0.5),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data) 
plot_nitrate(est_out = est_out, lake_data = lake_data) 
plot_maxUptake(est_out) 
#not plotting pred vs. obs or calculating RMSE here as the focus is on the behavior of the ensemble, not the forecast accuracy


```
## Objective 9: Explore data frequency
This objective will ask students to adjust the observation frequency (and therefore the assimilation frequency) of chl-a and nitrate data. The learning outcome of the objective is for students to understand that more frequency data assimilation may permit for more accurate forecasts, as models closely track real-world conditions. In addition, there may be opportunity for students to understand that one state variable may be corrected by assimilation of observations of a second state variable based on the covariance of the two; however, we need to decide if this is within or beyond our scope. In the Shiny app, students will use sliders to adjust the values of the chla_freq and din_freq arguments to the create_data_assim_inputs function. Below are three examples: one chla is assimilated at a high frequency and nitrate is assimilated at a low frequency, as well as the inverse and the scenario where both are assimilated at high frequency (daily).  

### High chl-a assimilation frequency
```{r}
#format observation data file depending on selected frequency of data assimilation
obs_file <- create_data_assim_inputs(freq_chla = 1,
                                     freq_din = 30,
                                     lake_data = lake_data,
                                     start_date = start_date)

n_en = 30 # how many ensemble members 

#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-09-25', # start date 
           stop = '2020-10-29', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data) 
plot_nitrate(est_out = est_out, lake_data = lake_data) 
plot_maxUptake(est_out) 
pred_v_obs_chla(est_out = est_out, lake_data = lake_data)
pred_v_obs_nitrate(est_out = est_out, lake_data = lake_data)
rmse(est_out = est_out, lake_data = lake_data)
```

### High nitrate assimilation frequency
```{r}
#format observation data file depending on selected frequency of data assimilation
obs_file <- create_data_assim_inputs(freq_chla = 30,
                                     freq_din = 1,
                                     lake_data = lake_data,
                                     start_date = start_date)

n_en = 30 # how many ensemble members 

#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-09-25', # start date 
           stop = '2020-10-29', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data) 
plot_nitrate(est_out = est_out, lake_data = lake_data) 
plot_maxUptake(est_out) 
pred_v_obs_chla(est_out = est_out, lake_data = lake_data)
pred_v_obs_nitrate(est_out = est_out, lake_data = lake_data)
rmse(est_out = est_out, lake_data = lake_data)
```

### High chl-a and nitrate assimilation frequency
```{r}
#format observation data file depending on selected frequency of data assimilation
obs_file <- create_data_assim_inputs(freq_chla = 1,
                                     freq_din = 1,
                                     lake_data = lake_data,
                                     start_date = start_date)

n_en = 30 # how many ensemble members 

#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-09-25', # start date 
           stop = '2020-10-29', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data) 
plot_nitrate(est_out = est_out, lake_data = lake_data) 
plot_maxUptake(est_out) 
pred_v_obs_chla(est_out = est_out, lake_data = lake_data)
pred_v_obs_nitrate(est_out = est_out, lake_data = lake_data)
rmse(est_out = est_out, lake_data = lake_data)
```
##Objective 10: Assess cost vs benefit of an expensive, more reliable sensor  
This objective will ask students to choose between purchasing an inexpensive, less reliable sensor vs. an expensive, more reliable sensor to generate forecasts in a drinking water reservoir. I'm using BARC under the hood and the forecast is for 2020-10-02, so the data will look a little different from Activities A and B b/c students forecast from 2020-09-25 for those activities. (Hopefully avoiding students realizing it's just rehashed Barco data.)
### Set-up
```{r}
# Load in NEON sites dataframe ----
neon_sites_df <- read.csv("./app/data/neon_sites.csv")
neon_sites_df$long <- round(neon_sites_df$long, 3)
neon_sites_df$lat <- round(neon_sites_df$lat, 3)

# Reference for downloading variables ----
neon_vars <- read.csv("./app/data/neon_variables.csv")

# Objective 1 - Site Selection ----
print(neon_sites_df$siteID)
#we have BARC, CRAM, LIRO, PRLA, PRPO, SUGG, TOOK
#need to think about which sites we want to use for Mod 7 based on how they behave in app testing
siteID <- "BARC"

#set start date of forecast
start_date = "2020-10-02" 

#load NEON data and format for input into EnKF
lake_data <- format_enkf_inputs(siteID = siteID, neon_vars = neon_vars)

#get initial conditions for forecast
yini <- get_yini(lake_data = lake_data,
                 start_date = start_date)

#load NOAA GEFS forecast
fc <- load_noaa_forecast(siteID = siteID, start_date = start_date)

#get regression for water temp
lm_wt <- get_NEON_lm(siteID = siteID, x = "Air temperature",
                     y = "Surface water temperature", start_date = start_date)

#get regression for upar
lm_upar <- get_NEON_lm(siteID = siteID, x = "Shortwave radiation",
                     y = "Underwater PAR", start_date = start_date)

#convert NOAA GEFS forecast to water temp and upar forecast
driver_file <- convert_forecast(lm_wt = lm_wt, lm_upar = lm_upar, fc = fc, start_date = start_date)
```
### Run forecast with "cheap" sensor  
In this case, inserting 36 as the frequency of nitrate assimilation ensures that only the first observation in the 35 day observation period will be assimilated. We'll then manually introduce a data gap in the dataset and set the observation uncertainty to be greater than for the more expensive, reliable sensor. The length of the data gap and the exact magnitude of observation error are randomly drawn within specified limits. The idea behind drawing them randomly is that sometimes the forecast with the cheap sensor is "good enough" to avoid triggering a management action (which the scenario sets up to be triggered if chl-a is over 10 mg/L), and sometimes the cheap sensor incorrectly predicts that chl-a will be over 10 mg/L, thus triggering an unnecessary management action, depending on the duration of the data gap and magnitude of observation error. This means that different students could get different answers about whether investment in the expensive sensor is worth it. If we don't like this way of approaching it I'm totally happy to revisit!
```{r}
#format observation data file depending on selected frequency of data assimilation

obs_file <- create_data_assim_inputs(freq_chla = 1,
                                     freq_din = 36,
                                     lake_data = lake_data,
                                     start_date = start_date)

#manually introduce semi-random gap representing sensor malfunction
start_gap <- sample(5:25,1)
gap_length <- sample(1:5,1)
gap = seq(start_gap, start_gap+gap_length, 1)
obs_file[c(gap),"chla"] <- NA

n_en = 30 # how many ensemble members 

#randomly draw for observation uncertainty within limits
obs_cv_chla <- runif(1,0.2,0.4)

#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-10-02', # start date 
           stop = '2020-10-31', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(obs_cv_chla,0.05),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data)
abline(h = 10, col = "darkgreen",lty = "dashed",lwd = 3)

pred_v_obs_chla(est_out = est_out, lake_data = lake_data)

rmse(est_out = est_out, lake_data = lake_data)


```
### Run forecast with expensive sensor  
In this case, inserting 36 as the frequency of nitrate assimilation ensures that only the first observation in the 35 day observation period will be assimilated. We'll then set the observation uncertainty to be less than for the cheaper, less reliable sensor. We also won't introduce any data gaps. The forecast using the reliable sensor is always "good enough" to avoid triggering a management action (which the scenario sets up to be triggered if chl-a is over 10 mg/L). 
```{r}
#format observation data file depending on selected frequency of data assimilation

obs_file <- create_data_assim_inputs(freq_chla = 1,
                                     freq_din = 36,
                                     lake_data = lake_data,
                                     start_date = start_date)

n_en = 30 # how many ensemble members 

#run the forecast!
est_out = EnKF(n_en = n_en, 
           start = '2020-10-02', # start date 
           stop = '2020-10-31', # stop date
           time_step = 'days',
           obs_file = obs_file,
           driver_file = driver_file,
           n_states_est = 2, 
           n_params_est = 1,
           n_params_obs = 0,
           maxUptake_init = 0.12, 
           obs_cv = c(0.1,0.05),#cv for chl-a and DIN, respectively
           param_cv = 0.1,#for maxUptake
           init_cond_cv = c(0.1,0.1),#cv for chl-a and DIN, respectively
           state_names = c("chla","din"),
           yini = yini)

#plot forecast output
plot_chla(est_out = est_out, lake_data = lake_data)
abline(h = 10, col = "darkgreen",lty = "dashed",lwd = 3)

pred_v_obs_chla(est_out = est_out, lake_data = lake_data)

rmse(est_out = est_out, lake_data = lake_data)


```
